# -*- coding: utf-8 -*-
"""EDA sample.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m95hMgSvUW4WjiDnZ8GlkvmDSniaDgGh
"""

from google.colab import drive
drive.mount('/content/drive')

import os, numpy as np, pandas as pd, matplotlib.pyplot as plt

BASE = "/content/drive/MyDrive/Capstone Project/Data"
SRC_CLEAN = f"{BASE}/processed/fact_production_clean.csv"
SRC_RAW   = f"{BASE}/processed/fact_production.csv"
src = SRC_CLEAN if os.path.exists(SRC_CLEAN) else SRC_RAW
print("Reading:", src)

df = pd.read_csv(src, parse_dates=["Date"])

# ---- minimal clean for cost analysis ----
num_cols = ["Served_Total","Offered_Total","Planned_Total",
            "Discarded_Total","Leftover_Total","Production_Cost_Total",
            "Cost_per_Meal","Waste_Qty","Waste_Rate"]
for c in num_cols:
    if c in df.columns: df[c] = pd.to_numeric(df[c], errors="coerce")

df["Meal"] = df["Meal"].astype(str)
df = df[df["Date"].notna() & df["Meal"].isin(["Breakfast","Lunch"]) & df["School_Code"].astype(str).str.len().gt(0)].copy()

# derive Cost_per_Meal if missing
if "Cost_per_Meal" not in df.columns or df["Cost_per_Meal"].isna().all():
    df["Cost_per_Meal"] = np.where(df.get("Served_Total",0)>0,
                                   df.get("Production_Cost_Total",np.nan)/df["Served_Total"],
                                   np.nan)

# derive Waste_Qty / Waste_Rate if missing
if "Waste_Qty" not in df.columns or df["Waste_Qty"].isna().all():
    disc, left = df.get("Discarded_Total"), df.get("Leftover_Total")
    off,  srv  = df.get("Offered_Total"), df.get("Served_Total")
    df["Waste_Qty"] = np.where(disc.notna() & (disc>0), disc,
                        np.where(left.notna() & (left>0), left,
                                 np.where(off.notna() & srv.notna(), (off-srv).clip(lower=0), np.nan)))
if "Waste_Rate" not in df.columns or df["Waste_Rate"].isna().all():
    df["Waste_Rate"] = np.where(df.get("Offered_Total",0)>0, df["Waste_Qty"]/df["Offered_Total"], np.nan)

# clip negatives on counts
for c in ["Served_Total","Offered_Total","Planned_Total","Discarded_Total","Leftover_Total","Waste_Qty"]:
    if c in df.columns: df[c] = df[c].clip(lower=0)

# analysis subset: rows usable for cost-per-meal
dfc = df[(df.get("Served_Total",0)>0) & (df.get("Production_Cost_Total",0)>0)].copy()

# choose a waste feature with best coverage (true rate vs proxy)
rate_cov  = dfc["Waste_Rate"].notna().mean() if "Waste_Rate" in dfc.columns else 0
proxy_cov = ((dfc.get("Offered_Total").notna()) & (dfc.get("Served_Total").notna())).mean() if "Offered_Total" in dfc.columns else 0
if proxy_cov > rate_cov:
    dfc["Waste_Rate_Chosen"] = ((dfc["Offered_Total"] - dfc["Served_Total"]).clip(lower=0) / dfc["Offered_Total"])
    chosen_label = "Waste_Rate (proxy)"
else:
    dfc["Waste_Rate_Chosen"] = dfc["Waste_Rate"]
    chosen_label = "Waste_Rate"

print("Rows usable:", len(dfc), "| Schools:", dfc["School_Code"].nunique(),
      "| Dates:", dfc["Date"].min().date(), "→", dfc["Date"].max().date(),
      "| Using:", chosen_label)

# ---------- (A) Spearman correlation heatmap (district) ----------
cols = ["Cost_per_Meal","Served_Total","Waste_Rate_Chosen",
        "Offered_Total","Planned_Total","Production_Cost_Total"]
have = [c for c in cols if c in dfc.columns]
corr = dfc[have].corr(method="spearman")

plt.figure(figsize=(6,5))
im = plt.imshow(corr.values, aspect='auto')
plt.title("Spearman correlation — District (daily school×meal)")
plt.xticks(range(len(have)), have, rotation=45, ha='right')
plt.yticks(range(len(have)), have)
plt.colorbar(im, fraction=0.046, pad=0.04)
for i in range(len(have)):
    for j in range(len(have)):
        plt.text(j, i, f"{corr.values[i,j]:.2f}", ha="center", va="center", fontsize=9)
plt.tight_layout(); plt.show()

# Print the key relationships you’ll cite
if "Cost_per_Meal" in corr.columns:
    c_vs_served = corr.loc["Cost_per_Meal","Served_Total"] if "Served_Total" in corr.index else np.nan
    c_vs_waste  = corr.loc["Cost_per_Meal","Waste_Rate_Chosen"] if "Waste_Rate_Chosen" in corr.index else np.nan
    print(f"Correlation vs Cost_per_Meal — Served_Total: {c_vs_served:.2f} (expect negative)")
    print(f"Correlation vs Cost_per_Meal — {chosen_label}: {c_vs_waste:.2f} (expect positive)")

# ---------- (B) One binned scatter with trend: Cost/Meal vs Participation ----------
def binned_trend(x, y, bins=18):
    q = np.linspace(0,1,bins+1)
    edges = np.unique(np.quantile(x[~np.isnan(x)], q))
    idx = np.digitize(x, edges[1:-1], right=True)
    x_mean = pd.Series(x).groupby(idx).mean()
    y_mean = pd.Series(y).groupby(idx).mean()
    return x_mean.values, y_mean.values

sub_all = dfc.dropna(subset=["Served_Total","Cost_per_Meal"]).copy()
x_b, y_b = binned_trend(sub_all["Served_Total"].values, sub_all["Cost_per_Meal"].values, bins=18)

# Spearman (robust to non-linear monotone relationship)
try:
    from scipy.stats import spearmanr
    rho, p = spearmanr(sub_all["Served_Total"], sub_all["Cost_per_Meal"])
except Exception:
    rho, p = np.nan, np.nan

plt.figure(figsize=(9,6))
plt.scatter(sub_all["Served_Total"], sub_all["Cost_per_Meal"], s=6, alpha=0.2, label="Daily points")
plt.plot(x_b, y_b, linewidth=3, label="Binned average trend")
plt.title(f"Cost per meal vs Participation (all schools & meals)\nSpearman ρ={rho:.2f} (lower is better)")
plt.xlabel("Meals served (participation)")
plt.ylabel("Cost per meal")
plt.legend()
plt.tight_layout()
plt.show()

# Simple effect size you can quote: bottom vs top participation quintile
sub_all["served_q"] = pd.qcut(sub_all["Served_Total"], 5, labels=False, duplicates="drop")
lo = sub_all[sub_all["served_q"]==0]["Cost_per_Meal"].median()
hi = sub_all[sub_all["served_q"]==sub_all["served_q"].max()]["Cost_per_Meal"].median()
print(f"Median Cost/Meal at LOW participation={lo:.2f} vs HIGH={hi:.2f}  → Δ={(lo-hi):.2f}")

