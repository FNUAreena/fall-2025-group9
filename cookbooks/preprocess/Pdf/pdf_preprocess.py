# -*- coding: utf-8 -*-
"""PDF preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tdholOJF2CmBwLv1HcDz_e7TBPvJSFGn
"""

!pip -q install pandas numpy pyarrow openpyxl beautifulsoup4 lxml pdfplumber PyPDF2 regex scikit-learn statsmodels plotly streamlit dateparser

from google.colab import drive
drive.mount('/content/drive')

# ============================================
# FCPS POS PDFs -> CSV  (Single-file Colab Script; IN_COLAB fixed)
# ============================================

# 0) Install deps
try:
    import pdfplumber, PyPDF2, pandas  # noqa: F401
except Exception:
    import sys, subprocess
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "pdfplumber", "PyPDF2", "pandas"])

# 1) Mount Drive (define IN_COLAB safely first)
IN_COLAB = False
try:
    from google.colab import drive  # type: ignore
    drive.mount("/content/drive")
    IN_COLAB = True
except Exception:
    print("google.colab not found; continuing without Drive mount (running outside Colab?)")

# 2) Paths (change SRC_DIR if your PDFs live elsewhere)
SRC_DIR = "/content/drive/MyDrive/Capstone Project/Data/Item Sales Reports - Mar May 2025/Item Sales Reports - Mar May 2025"
OUT_DIR = "/content/drive/MyDrive/Capstone Project/Data/preprocess/pos-processing/preprocessed-data"
OUT_CSV = f"{OUT_DIR}/pdf preprocess.csv"

# 3) Parser (same logic as before)
import os, re, glob, logging
from typing import List, Tuple, Iterable, Optional
import pandas as pd

logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s")

try:
    import pdfplumber
except Exception:
    pdfplumber = None

try:
    from PyPDF2 import PdfReader
except Exception:
    PdfReader = None

OUT_COLS = [
    "School_Code","School_Name","Date","Meal",
    "Item_Code","Item_Desc","Sold_Total",
    "Free_Meals","Reduced_Meals","Paid_Meals",
    "Adult_Count","ALaCarte_Student","ALaCarte_Adult"
]

def _safe_int(x: str) -> int:
    x = str(x).strip().replace(",", "")
    return int(x) if re.fullmatch(r"-?\d+", x) else 0

def _normalize_ws(s: str) -> str:
    return re.sub(r"\s+", " ", s or "").strip()

def guess_meal_from_filename(fname: str) -> str:
    n = os.path.basename(fname).lower()
    if "breakfast" in n: return "Breakfast"
    if "lunch" in n:     return "Lunch"
    return "Unknown"

def parse_meta(text: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
    school_code, school_name, date = None, None, None
    m = re.search(r"Site:\s*(\d{2,10})\s+(.+?)(?:\n|$)", text)
    if m:
        school_code = m.group(1)
        school_name = _normalize_ws(m.group(2))
    d = re.search(r"(Session\s*Date|Date):\s*([0-9]{1,2}/[0-9]{1,2}/[0-9]{2,4})", text, re.I)
    if d:
        date = d.group(2)
    return school_code, school_name, date

def _find_data_start(lines: List[str]) -> int:
    for i, l in enumerate(lines):
        if ("item" in l.lower() and "description" in l.lower() and "total" in l.lower()):
            return i + 1
    for i, l in enumerate(lines):
        if re.match(r"^\s*\d{2,}\s+", l):
            return i
    return 0

def _iter_item_blocks(lines: Iterable[str]) -> Iterable[dict]:
    cur = None
    for raw in lines:
        t = raw.rstrip()
        if not t:
            continue
        if re.search(r"GRAND\s+TOTALS?", t, re.I):
            if cur:
                yield cur
            return
        m = re.match(r"^\s*(\d{2,})\s+(.+)$", t)
        if m:
            if cur:
                yield cur
            cur = {"Item_Code": m.group(1), "desc": m.group(2)}
        else:
            if cur:
                cur["desc"] += " " + t.strip()
    if cur:
        yield cur

def _split_desc_and_numbers(desc: str):
    toks = desc.split()
    nums, cut = [], len(toks)
    for i in range(len(toks)-1, -1, -1):
        if re.fullmatch(r"-?\d+", toks[i].replace(",", "")):
            nums.append(_safe_int(toks[i])); cut = i
        else:
            break
    nums.reverse()
    clean_desc = " ".join(toks[:cut]).strip()
    return clean_desc, nums

def _numbers_to_columns(nums):
    padded = (nums + [0]*7)[:7]
    return tuple(padded)

def _extract_text_pdfplumber(path: str) -> List[str]:
    texts = []
    with pdfplumber.open(path) as pdf:
        for p in pdf.pages:
            texts.append(p.extract_text() or "")
    return texts

def _extract_text_pypdf2(path: str) -> List[str]:
    texts = []
    r = PdfReader(path)
    for page in r.pages:
        texts.append(page.extract_text() or "")
    return texts

def parse_pdf(path: str) -> pd.DataFrame:
    meal = guess_meal_from_filename(path)
    rows = []
    page_texts: List[str] = []

    if pdfplumber is not None:
        try:
            page_texts = _extract_text_pdfplumber(path)
        except Exception as e:
            logging.warning(f"pdfplumber failed on {os.path.basename(path)}: {e}")

    if (not page_texts or all(not (t or "").strip() for t in page_texts)) and PdfReader is not None:
        try:
            page_texts = _extract_text_pypdf2(path)
        except Exception as e:
            logging.warning(f"PyPDF2 failed on {os.path.basename(path)}: {e}")

    if not page_texts:
        logging.error(f"No text extracted from {path}")
        return pd.DataFrame(columns=OUT_COLS)

    for txt in page_texts:
        if not (txt or "").strip():
            continue
        code, name, date = parse_meta(txt)
        lines = txt.splitlines()
        data_lines = lines[_find_data_start(lines):]
        for blk in _iter_item_blocks(data_lines):
            desc_raw = _normalize_ws(blk.get("desc", ""))
            desc, nums = _split_desc_and_numbers(desc_raw)
            sold, free_m, red_m, paid_m, adult_c, alac_s, alac_a = _numbers_to_columns(nums)
            rows.append([
                code or "", name or "", date or "", meal,
                blk["Item_Code"], desc, sold,
                free_m, red_m, paid_m,
                adult_c, alac_s, alac_a
            ])

    if not rows:
        logging.warning(f"No rows parsed from {path}")
        return pd.DataFrame(columns=OUT_COLS)

    df = pd.DataFrame(rows, columns=OUT_COLS)
    for c in ("Sold_Total","Free_Meals","Reduced_Meals","Paid_Meals","Adult_Count","ALaCarte_Student","ALaCarte_Adult"):
        df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)
    return df

def parse_folder(src_folder: str, out_csv: str, recursive: bool = True, pattern: str = "*.pdf") -> pd.DataFrame:
    if not os.path.isdir(src_folder):
        raise FileNotFoundError(f"Source folder not found: {src_folder}")
    glob_pat = "**/" + pattern if recursive else pattern
    files = sorted(glob.glob(os.path.join(src_folder, glob_pat), recursive=recursive))
    if not files:
        logging.error(f"No PDFs found in: {src_folder}")
        return pd.DataFrame(columns=OUT_COLS)

    logging.info(f"Found {len(files)} PDF(s) in {src_folder}")
    dfs = []
    for i, f in enumerate(files, 1):
        logging.info(f"[{i}/{len(files)}] Parsing {os.path.basename(f)}")
        df = parse_pdf(f)
        if len(df):
            dfs.append(df)

    if not dfs:
        logging.error("No data parsed from any PDF.")
        return pd.DataFrame(columns=OUT_COLS)

    full = pd.concat(dfs, ignore_index=True).sort_values(["School_Code","Date","Item_Code"])
    os.makedirs(os.path.dirname(out_csv), exist_ok=True)
    full.to_csv(out_csv, index=False)
    logging.info(f"Saved CSV â†’ {out_csv}")
    return full

# 4) Run
os.makedirs(OUT_DIR, exist_ok=True)
df = parse_folder(SRC_DIR, OUT_CSV, recursive=True, pattern="*.pdf")

if not df.empty:
    print(df.head(15).to_string(index=False))
    print(f"\nRows parsed: {len(df):,}")
    print("CSV written to:", OUT_CSV)
else:
    print("No rows parsed. Check your SRC_DIR path and PDF format.")

# 5) Tips (won't NameError anymore)
if IN_COLAB:
    print("\nDrive path tips:")
    print("  Source PDFs :", SRC_DIR)
    print("  Output CSV  :", OUT_CSV)

